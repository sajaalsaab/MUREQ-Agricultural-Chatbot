{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A1doVMd9VhtQ"
      },
      "source": [
        "# install prerequisite"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GA7AjkqBkyZb",
        "outputId": "58a918d5-8f82-42b4-ed36-f212e20dd144"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla T4\n",
            "Sat May  4 15:26:42 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   69C    P8              11W /  70W |      3MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():\n",
        "\n",
        "    # Tell PyTorch to use the GPU.\n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "    !nvidia-smi\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v7zsC6CBXlL4"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import BertTokenizerFast\n",
        "from transformers import AutoTokenizer, AutoModelForQuestionAnswering, AdamW\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "675fapwYnwWe",
        "outputId": "77cafcf6-f2bc-4ee3-e15e-181ee188e4aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set informaiton:\n",
            "Length of each training array is 847 elements\n",
            "The first 5 Questions of Training array:\n",
            "['ماذا يسبب تعرض النباتات لدرجات حرارة منحفضة؟', 'ماهي شجرة اللبخ؟', 'ماهي طريقة زراعة شجرة اللبخ؟', 'ماهي الأماكن المناسبة لزراعة شجرة اللبخ؟', 'ماهو المناخ المثالي لزراعة شجرة اللبخ؟']\n",
            "**********\n",
            "Validation set informaiton:\n",
            "Length of each Validation array is 107 elements\n",
            "The first 5 Questions of Validation array:\n",
            "['ماهي نبتة الفيروكاكتوس ؟', 'ماهي طريقة زراعة نبتة الفيروكاكتوس ؟ ', 'ماهي طريقة العناية بنبتة الفيروكاكتوس ؟', 'ماهو المناخ المناسب لنبتة الفيروكاكتوس ؟', 'ماهي الأمراض التي تصيب نبتة الفيروكاكتوس؟']\n",
            "**********\n",
            "Testing set informaiton:\n",
            "Length of each testing array is 108 elemants\n",
            "The first 5 Questions of Testing array:\n",
            "['ماهو نبات دراسينا؟', 'ماهي طريقة زراعة نبات دراسينا؟ ', 'ماهي طريقة العناية بنبات دراسينا؟', 'ماهو المناخ المناسب لنبات دراسينا؟', 'ماهي الأمراض التي تصيب نبات دراسينا؟']\n"
          ]
        }
      ],
      "source": [
        "def read_QA(path):\n",
        "    with open(path, 'rb') as f:\n",
        "        QA_dict = json.load(f)\n",
        "\n",
        "    contexts = []\n",
        "    questions = []\n",
        "    answers = []\n",
        "    for item in QA_dict['data']:\n",
        "      for paragraph in item['paragraphs']:\n",
        "        context = paragraph['context']\n",
        "        for qa in paragraph['qas']:\n",
        "            question = qa['question']\n",
        "            for answer in qa['answers']:\n",
        "                    contexts.append(context)\n",
        "                    questions.append(question)\n",
        "                    answers.append(answer)\n",
        "    max_context_length = max(len(context) for context in contexts)\n",
        "    max_answer_length = max(len(answer['text']) for answer in answers)\n",
        "    max_question_length = max(len(question) for question in questions)\n",
        "\n",
        "\n",
        "    #print(\"Maximum context length:\", max_context_length)\n",
        "    #print(\"Maximum question length:\", max_question_length)\n",
        "    #print(\"Maximum answer length:\", max_answer_length)\n",
        "\n",
        "    return contexts, questions, answers\n",
        "print(\"Training set informaiton:\")\n",
        "train_contexts, train_questions, train_answers = read_QA('/content/train (1).json')\n",
        "print(f\"Length of each training array is {len(train_contexts)} elements\")\n",
        "print(f\"The first 5 Questions of Training array:\\n{train_questions[:5]}\")\n",
        "print('*'*10)\n",
        "print(\"Validation set informaiton:\")\n",
        "val_contexts, val_questions, val_answers = read_QA('/content/test (1).json')\n",
        "print(f\"Length of each Validation array is {len(val_contexts)} elements\")\n",
        "print(f\"The first 5 Questions of Validation array:\\n{val_questions[:5]}\")\n",
        "print('*'*10)\n",
        "print(\"Testing set informaiton:\")\n",
        "test_contexts, test_questions, test_answers = read_QA('/content/val (1).json')\n",
        "print(f\"Length of each testing array is {len(test_contexts)} elemants\")\n",
        "print(f\"The first 5 Questions of Testing array:\\n{test_questions[:5]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kdyN0Q45MFru"
      },
      "source": [
        "# **Add start and end for every answer**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fviB2QCAI7gk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed6358a5-948c-495f-a60b-799b15f56e34"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A sample of train answers array before adding 'answer_end' : {'text': 'ظهور بقع سوداء أو بيضاء غير منتظمة.', 'answer_start': 324}\n",
            "A sample of train answers array after adding 'answer_end' :{'text': 'ظهور بقع سوداء أو بيضاء غير منتظمة.', 'answer_start': 324, 'answer_end': 359}\n"
          ]
        }
      ],
      "source": [
        "print(f\"A sample of train answers array before adding 'answer_end' : {train_answers[0]}\")\n",
        "def add_start_end_idx(answers, contexts):\n",
        "    for answer, context in zip(answers, contexts):\n",
        "        gold_text = answer['text']\n",
        "        start_idx = context.index(gold_text,0)\n",
        "        end_idx = start_idx + len(gold_text)\n",
        "\n",
        "        if context[start_idx:end_idx] == gold_text:\n",
        "            answer['answer_start'] = start_idx\n",
        "            answer['answer_end'] = end_idx\n",
        "\n",
        "\n",
        "add_start_end_idx(train_answers, train_contexts)\n",
        "add_start_end_idx(val_answers, val_contexts)\n",
        "add_start_end_idx(test_answers, test_contexts)\n",
        "print(f\"A sample of train answers array after adding 'answer_end' :{train_answers[0]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YtcApiwYL0-8"
      },
      "source": [
        "# ***  Preprocessing step for context ***\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mjwHY8ZO9nXQ"
      },
      "outputs": [],
      "source": [
        "# from arabert.preprocess import ArabertPreprocessor\n",
        "\n",
        "# model_name = 'aubmindlab/bert-base-arabertv02'\n",
        "# arabert_prep = ArabertPreprocessor(model_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YRPgTUFD9p9G"
      },
      "outputs": [],
      "source": [
        "# # Applying the arabert preprocessor to the 'train_context'\n",
        "# preprocessed_tarined_contexts = []\n",
        "# for context in train_contexts:\n",
        "#     preprocessed_context = arabert_prep.preprocess(context)\n",
        "#     preprocessed_tarined_contexts.append(preprocessed_context)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s8cASQ_kAsx9"
      },
      "outputs": [],
      "source": [
        "# # Applying the arabert preprocessor to the 'val_context'\n",
        "# preprocessed_val_contexts = []\n",
        "# for context in val_contexts:\n",
        "#     preprocessed_context = arabert_prep.preprocess(context)\n",
        "#     preprocessed_val_contexts.append(preprocessed_context)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5XFX3CPRLljp"
      },
      "source": [
        "# **Making sure every answer has an end key**\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B0TNan_HQ44m"
      },
      "outputs": [],
      "source": [
        "def find_dicts_without_answer_end(answers):\n",
        "    dicts_without_answer_end = []\n",
        "    for i, answer_dict in enumerate(answers):\n",
        "        if 'answer_end' not in answer_dict:\n",
        "            dicts_without_answer_end.append((i, answer_dict))\n",
        "    return dicts_without_answer_end"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7np4vOheTBNt",
        "outputId": "111821fe-083a-4aca-f666-2cf6763bf7ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All dictionaries in train_answers have 'answer_end' key.\n"
          ]
        }
      ],
      "source": [
        "dicts_without_answer_end = find_dicts_without_answer_end(train_answers)\n",
        "if dicts_without_answer_end:\n",
        "    print(\"Dictionaries without 'answer_end' key:\")\n",
        "    for index, answer_dict in dicts_without_answer_end:\n",
        "        print(f\"Index: {index}, Dictionary: {answer_dict}\")\n",
        "else:\n",
        "    print(\"All dictionaries in train_answers have 'answer_end' key.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QCnckdliTCIT",
        "outputId": "96a123fc-c39a-43e0-be0c-97ddb111874f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All dictionaries in val_answers have 'answer_end' key.\n"
          ]
        }
      ],
      "source": [
        "dicts_without_answer_end = find_dicts_without_answer_end(val_answers)\n",
        "if dicts_without_answer_end:\n",
        "    print(\"Dictionaries without 'answer_end' key:\")\n",
        "    for index, answer_dict in dicts_without_answer_end:\n",
        "        print(f\"Index: {index}, Dictionary: {answer_dict}\")\n",
        "else:\n",
        "    print(\"All dictionaries in val_answers have 'answer_end' key.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0M57cxvjXMaw",
        "outputId": "30b2d6bb-fe16-4c85-e847-356f594c4296"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All dictionaries in test_answers have 'answer_end' key.\n"
          ]
        }
      ],
      "source": [
        "dicts_without_answer_end = find_dicts_without_answer_end(test_answers)\n",
        "if dicts_without_answer_end:\n",
        "    print(\"Dictionaries without 'answer_end' key:\")\n",
        "    for index, answer_dict in dicts_without_answer_end:\n",
        "        print(f\"Index: {index}, Dictionary: {answer_dict}\")\n",
        "else:\n",
        "    print(\"All dictionaries in test_answers have 'answer_end' key.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NaNdnajX8GJ6"
      },
      "source": [
        "# **Tokenizer**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J5xfTypWMkBz",
        "outputId": "0037e999-2d96-4f0f-8f8e-2d56e8058dcf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained('MMars/Question_Answering_AraBERT_xtreme_ar')\n",
        "train_encodings = tokenizer(train_contexts, train_questions, truncation=True, padding=True)\n",
        "val_encodings = tokenizer(val_contexts, val_questions, truncation=True, padding=True)\n",
        "test_encodings = tokenizer(test_contexts, test_questions, truncation=True, padding=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Encodings before: {train_encodings[1]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "geXvaVM1SrT7",
        "outputId": "acd3a5a2-f31e-410c-e14f-91c303f9778a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encodings before: Encoding(num_tokens=463, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xIV3UxJhM6xr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2aa2f701-db1e-426f-da98-8ae9cf3f7d90"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encodings after: Encoding(num_tokens=463, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])\n"
          ]
        }
      ],
      "source": [
        "def add_token_positions(encodings, answers):\n",
        "    start_positions = []\n",
        "    end_positions = []\n",
        "    for i in range(len(answers)):\n",
        "        start_positions.append(encodings.char_to_token(i, answers[i]['answer_start']))\n",
        "        end_positions.append(encodings.char_to_token(i, answers[i]['answer_end']-1))\n",
        "        # if None, the answer passage has been truncated\n",
        "        if start_positions[-1] is None:\n",
        "            start_positions[-1] = tokenizer.model_max_length\n",
        "        if end_positions[-1] is None:\n",
        "            end_positions[-1] = tokenizer.model_max_length\n",
        "    encodings.update({'start_positions': start_positions, 'end_positions': end_positions})\n",
        "\n",
        "add_token_positions(train_encodings, train_answers)\n",
        "add_token_positions(val_encodings, val_answers)\n",
        "add_token_positions(test_encodings, test_answers)\n",
        "print(f\"Encodings after: {train_encodings[1]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "21Rnvrx2YKA9"
      },
      "source": [
        "# Dataset loader and model setting\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NhfiOXMPWIrO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "590848c8-71d1-4ae2-b95b-f23b0f3553f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A sample of train answers after tokanization :\n",
            " {'input_ids': tensor([    2, 13461, 34291,   200, 19673,  1585,   121, 12190, 28096,   103,\n",
            "         1034,   306, 19304, 20950, 10564,  1281,   103, 58608,   181, 14227,\n",
            "         2136, 28611,   103, 26667, 28611,   103, 35579,   305,  3631, 17197,\n",
            "         1557,   305,  1282,   773,  1160,   103, 31801,   465,   233,   199,\n",
            "        52117,   103, 17056, 54267, 10221,  1305, 47292,  3165,    20,  9733,\n",
            "        47554, 26932, 31045,  1338,  2077,   420, 41768, 21136,   324,  9309,\n",
            "          914, 57362,   315, 46055,   817, 10216,   201,  6912, 17243, 12368,\n",
            "         1632,  6289,   383,  1377,   816, 56067,   198,  1693,   563,   829,\n",
            "          819, 49675,   401,  1023,   802,    20,     3, 25830, 13461, 34291,\n",
            "          200,   105,     3,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0]), 'start_positions': tensor(1), 'end_positions': tensor(47)}\n"
          ]
        }
      ],
      "source": [
        "class QADataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings):\n",
        "        self.encodings = encodings\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.encodings.input_ids)\n",
        "\n",
        "train_dataset = QADataset(train_encodings)\n",
        "val_dataset = QADataset(val_encodings)\n",
        "test_dataset = QADataset(test_encodings)\n",
        "print(f\"A sample of train answers after tokanization :\\n {train_dataset[1]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pHY_qbdNYB_r",
        "outputId": "10bad86f-0876-4c9e-cf54-f0a8c3cd238f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at aubmindlab/bert-base-arabertv02 and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "model = AutoModelForQuestionAnswering.from_pretrained('MMars/Question_Answering_AraBERT_xtreme_ar')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BUqJjfhMqXGF",
        "outputId": "de0b882a-fc5e-42fe-8195-b8b525b9d777"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameter: embeddings.word_embeddings.weight, requires_grad: True\n",
            "Parameter: embeddings.position_embeddings.weight, requires_grad: True\n",
            "Parameter: embeddings.token_type_embeddings.weight, requires_grad: True\n",
            "Parameter: embeddings.LayerNorm.weight, requires_grad: True\n",
            "Parameter: embeddings.LayerNorm.bias, requires_grad: True\n",
            "Parameter: encoder.layer.0.attention.self.query.weight, requires_grad: False\n",
            "Parameter: encoder.layer.0.attention.self.query.bias, requires_grad: False\n",
            "Parameter: encoder.layer.0.attention.self.key.weight, requires_grad: False\n",
            "Parameter: encoder.layer.0.attention.self.key.bias, requires_grad: False\n",
            "Parameter: encoder.layer.0.attention.self.value.weight, requires_grad: False\n",
            "Parameter: encoder.layer.0.attention.self.value.bias, requires_grad: False\n",
            "Parameter: encoder.layer.0.attention.output.dense.weight, requires_grad: False\n",
            "Parameter: encoder.layer.0.attention.output.dense.bias, requires_grad: False\n",
            "Parameter: encoder.layer.0.attention.output.LayerNorm.weight, requires_grad: False\n",
            "Parameter: encoder.layer.0.attention.output.LayerNorm.bias, requires_grad: False\n",
            "Parameter: encoder.layer.0.intermediate.dense.weight, requires_grad: False\n",
            "Parameter: encoder.layer.0.intermediate.dense.bias, requires_grad: False\n",
            "Parameter: encoder.layer.0.output.dense.weight, requires_grad: False\n",
            "Parameter: encoder.layer.0.output.dense.bias, requires_grad: False\n",
            "Parameter: encoder.layer.0.output.LayerNorm.weight, requires_grad: False\n",
            "Parameter: encoder.layer.0.output.LayerNorm.bias, requires_grad: False\n",
            "Parameter: encoder.layer.1.attention.self.query.weight, requires_grad: True\n",
            "Parameter: encoder.layer.1.attention.self.query.bias, requires_grad: True\n",
            "Parameter: encoder.layer.1.attention.self.key.weight, requires_grad: True\n",
            "Parameter: encoder.layer.1.attention.self.key.bias, requires_grad: True\n",
            "Parameter: encoder.layer.1.attention.self.value.weight, requires_grad: True\n",
            "Parameter: encoder.layer.1.attention.self.value.bias, requires_grad: True\n",
            "Parameter: encoder.layer.1.attention.output.dense.weight, requires_grad: True\n",
            "Parameter: encoder.layer.1.attention.output.dense.bias, requires_grad: True\n",
            "Parameter: encoder.layer.1.attention.output.LayerNorm.weight, requires_grad: True\n",
            "Parameter: encoder.layer.1.attention.output.LayerNorm.bias, requires_grad: True\n",
            "Parameter: encoder.layer.1.intermediate.dense.weight, requires_grad: True\n",
            "Parameter: encoder.layer.1.intermediate.dense.bias, requires_grad: True\n",
            "Parameter: encoder.layer.1.output.dense.weight, requires_grad: True\n",
            "Parameter: encoder.layer.1.output.dense.bias, requires_grad: True\n",
            "Parameter: encoder.layer.1.output.LayerNorm.weight, requires_grad: True\n",
            "Parameter: encoder.layer.1.output.LayerNorm.bias, requires_grad: True\n",
            "Parameter: encoder.layer.2.attention.self.query.weight, requires_grad: True\n",
            "Parameter: encoder.layer.2.attention.self.query.bias, requires_grad: True\n",
            "Parameter: encoder.layer.2.attention.self.key.weight, requires_grad: True\n",
            "Parameter: encoder.layer.2.attention.self.key.bias, requires_grad: True\n",
            "Parameter: encoder.layer.2.attention.self.value.weight, requires_grad: True\n",
            "Parameter: encoder.layer.2.attention.self.value.bias, requires_grad: True\n",
            "Parameter: encoder.layer.2.attention.output.dense.weight, requires_grad: True\n",
            "Parameter: encoder.layer.2.attention.output.dense.bias, requires_grad: True\n",
            "Parameter: encoder.layer.2.attention.output.LayerNorm.weight, requires_grad: True\n",
            "Parameter: encoder.layer.2.attention.output.LayerNorm.bias, requires_grad: True\n",
            "Parameter: encoder.layer.2.intermediate.dense.weight, requires_grad: True\n",
            "Parameter: encoder.layer.2.intermediate.dense.bias, requires_grad: True\n",
            "Parameter: encoder.layer.2.output.dense.weight, requires_grad: True\n",
            "Parameter: encoder.layer.2.output.dense.bias, requires_grad: True\n",
            "Parameter: encoder.layer.2.output.LayerNorm.weight, requires_grad: True\n",
            "Parameter: encoder.layer.2.output.LayerNorm.bias, requires_grad: True\n",
            "Parameter: encoder.layer.3.attention.self.query.weight, requires_grad: True\n",
            "Parameter: encoder.layer.3.attention.self.query.bias, requires_grad: True\n",
            "Parameter: encoder.layer.3.attention.self.key.weight, requires_grad: True\n",
            "Parameter: encoder.layer.3.attention.self.key.bias, requires_grad: True\n",
            "Parameter: encoder.layer.3.attention.self.value.weight, requires_grad: True\n",
            "Parameter: encoder.layer.3.attention.self.value.bias, requires_grad: True\n",
            "Parameter: encoder.layer.3.attention.output.dense.weight, requires_grad: True\n",
            "Parameter: encoder.layer.3.attention.output.dense.bias, requires_grad: True\n",
            "Parameter: encoder.layer.3.attention.output.LayerNorm.weight, requires_grad: True\n",
            "Parameter: encoder.layer.3.attention.output.LayerNorm.bias, requires_grad: True\n",
            "Parameter: encoder.layer.3.intermediate.dense.weight, requires_grad: True\n",
            "Parameter: encoder.layer.3.intermediate.dense.bias, requires_grad: True\n",
            "Parameter: encoder.layer.3.output.dense.weight, requires_grad: True\n",
            "Parameter: encoder.layer.3.output.dense.bias, requires_grad: True\n",
            "Parameter: encoder.layer.3.output.LayerNorm.weight, requires_grad: True\n",
            "Parameter: encoder.layer.3.output.LayerNorm.bias, requires_grad: True\n",
            "Parameter: encoder.layer.4.attention.self.query.weight, requires_grad: True\n",
            "Parameter: encoder.layer.4.attention.self.query.bias, requires_grad: True\n",
            "Parameter: encoder.layer.4.attention.self.key.weight, requires_grad: True\n",
            "Parameter: encoder.layer.4.attention.self.key.bias, requires_grad: True\n",
            "Parameter: encoder.layer.4.attention.self.value.weight, requires_grad: True\n",
            "Parameter: encoder.layer.4.attention.self.value.bias, requires_grad: True\n",
            "Parameter: encoder.layer.4.attention.output.dense.weight, requires_grad: True\n",
            "Parameter: encoder.layer.4.attention.output.dense.bias, requires_grad: True\n",
            "Parameter: encoder.layer.4.attention.output.LayerNorm.weight, requires_grad: True\n",
            "Parameter: encoder.layer.4.attention.output.LayerNorm.bias, requires_grad: True\n",
            "Parameter: encoder.layer.4.intermediate.dense.weight, requires_grad: True\n",
            "Parameter: encoder.layer.4.intermediate.dense.bias, requires_grad: True\n",
            "Parameter: encoder.layer.4.output.dense.weight, requires_grad: True\n",
            "Parameter: encoder.layer.4.output.dense.bias, requires_grad: True\n",
            "Parameter: encoder.layer.4.output.LayerNorm.weight, requires_grad: True\n",
            "Parameter: encoder.layer.4.output.LayerNorm.bias, requires_grad: True\n",
            "Parameter: encoder.layer.5.attention.self.query.weight, requires_grad: True\n",
            "Parameter: encoder.layer.5.attention.self.query.bias, requires_grad: True\n",
            "Parameter: encoder.layer.5.attention.self.key.weight, requires_grad: True\n",
            "Parameter: encoder.layer.5.attention.self.key.bias, requires_grad: True\n",
            "Parameter: encoder.layer.5.attention.self.value.weight, requires_grad: True\n",
            "Parameter: encoder.layer.5.attention.self.value.bias, requires_grad: True\n",
            "Parameter: encoder.layer.5.attention.output.dense.weight, requires_grad: True\n",
            "Parameter: encoder.layer.5.attention.output.dense.bias, requires_grad: True\n",
            "Parameter: encoder.layer.5.attention.output.LayerNorm.weight, requires_grad: True\n",
            "Parameter: encoder.layer.5.attention.output.LayerNorm.bias, requires_grad: True\n",
            "Parameter: encoder.layer.5.intermediate.dense.weight, requires_grad: True\n",
            "Parameter: encoder.layer.5.intermediate.dense.bias, requires_grad: True\n",
            "Parameter: encoder.layer.5.output.dense.weight, requires_grad: True\n",
            "Parameter: encoder.layer.5.output.dense.bias, requires_grad: True\n",
            "Parameter: encoder.layer.5.output.LayerNorm.weight, requires_grad: True\n",
            "Parameter: encoder.layer.5.output.LayerNorm.bias, requires_grad: True\n",
            "Parameter: encoder.layer.6.attention.self.query.weight, requires_grad: True\n",
            "Parameter: encoder.layer.6.attention.self.query.bias, requires_grad: True\n",
            "Parameter: encoder.layer.6.attention.self.key.weight, requires_grad: True\n",
            "Parameter: encoder.layer.6.attention.self.key.bias, requires_grad: True\n",
            "Parameter: encoder.layer.6.attention.self.value.weight, requires_grad: True\n",
            "Parameter: encoder.layer.6.attention.self.value.bias, requires_grad: True\n",
            "Parameter: encoder.layer.6.attention.output.dense.weight, requires_grad: True\n",
            "Parameter: encoder.layer.6.attention.output.dense.bias, requires_grad: True\n",
            "Parameter: encoder.layer.6.attention.output.LayerNorm.weight, requires_grad: True\n",
            "Parameter: encoder.layer.6.attention.output.LayerNorm.bias, requires_grad: True\n",
            "Parameter: encoder.layer.6.intermediate.dense.weight, requires_grad: True\n",
            "Parameter: encoder.layer.6.intermediate.dense.bias, requires_grad: True\n",
            "Parameter: encoder.layer.6.output.dense.weight, requires_grad: True\n",
            "Parameter: encoder.layer.6.output.dense.bias, requires_grad: True\n",
            "Parameter: encoder.layer.6.output.LayerNorm.weight, requires_grad: True\n",
            "Parameter: encoder.layer.6.output.LayerNorm.bias, requires_grad: True\n",
            "Parameter: encoder.layer.7.attention.self.query.weight, requires_grad: True\n",
            "Parameter: encoder.layer.7.attention.self.query.bias, requires_grad: True\n",
            "Parameter: encoder.layer.7.attention.self.key.weight, requires_grad: True\n",
            "Parameter: encoder.layer.7.attention.self.key.bias, requires_grad: True\n",
            "Parameter: encoder.layer.7.attention.self.value.weight, requires_grad: True\n",
            "Parameter: encoder.layer.7.attention.self.value.bias, requires_grad: True\n",
            "Parameter: encoder.layer.7.attention.output.dense.weight, requires_grad: True\n",
            "Parameter: encoder.layer.7.attention.output.dense.bias, requires_grad: True\n",
            "Parameter: encoder.layer.7.attention.output.LayerNorm.weight, requires_grad: True\n",
            "Parameter: encoder.layer.7.attention.output.LayerNorm.bias, requires_grad: True\n",
            "Parameter: encoder.layer.7.intermediate.dense.weight, requires_grad: True\n",
            "Parameter: encoder.layer.7.intermediate.dense.bias, requires_grad: True\n",
            "Parameter: encoder.layer.7.output.dense.weight, requires_grad: True\n",
            "Parameter: encoder.layer.7.output.dense.bias, requires_grad: True\n",
            "Parameter: encoder.layer.7.output.LayerNorm.weight, requires_grad: True\n",
            "Parameter: encoder.layer.7.output.LayerNorm.bias, requires_grad: True\n",
            "Parameter: encoder.layer.8.attention.self.query.weight, requires_grad: True\n",
            "Parameter: encoder.layer.8.attention.self.query.bias, requires_grad: True\n",
            "Parameter: encoder.layer.8.attention.self.key.weight, requires_grad: True\n",
            "Parameter: encoder.layer.8.attention.self.key.bias, requires_grad: True\n",
            "Parameter: encoder.layer.8.attention.self.value.weight, requires_grad: True\n",
            "Parameter: encoder.layer.8.attention.self.value.bias, requires_grad: True\n",
            "Parameter: encoder.layer.8.attention.output.dense.weight, requires_grad: True\n",
            "Parameter: encoder.layer.8.attention.output.dense.bias, requires_grad: True\n",
            "Parameter: encoder.layer.8.attention.output.LayerNorm.weight, requires_grad: True\n",
            "Parameter: encoder.layer.8.attention.output.LayerNorm.bias, requires_grad: True\n",
            "Parameter: encoder.layer.8.intermediate.dense.weight, requires_grad: True\n",
            "Parameter: encoder.layer.8.intermediate.dense.bias, requires_grad: True\n",
            "Parameter: encoder.layer.8.output.dense.weight, requires_grad: True\n",
            "Parameter: encoder.layer.8.output.dense.bias, requires_grad: True\n",
            "Parameter: encoder.layer.8.output.LayerNorm.weight, requires_grad: True\n",
            "Parameter: encoder.layer.8.output.LayerNorm.bias, requires_grad: True\n",
            "Parameter: encoder.layer.9.attention.self.query.weight, requires_grad: True\n",
            "Parameter: encoder.layer.9.attention.self.query.bias, requires_grad: True\n",
            "Parameter: encoder.layer.9.attention.self.key.weight, requires_grad: True\n",
            "Parameter: encoder.layer.9.attention.self.key.bias, requires_grad: True\n",
            "Parameter: encoder.layer.9.attention.self.value.weight, requires_grad: True\n",
            "Parameter: encoder.layer.9.attention.self.value.bias, requires_grad: True\n",
            "Parameter: encoder.layer.9.attention.output.dense.weight, requires_grad: True\n",
            "Parameter: encoder.layer.9.attention.output.dense.bias, requires_grad: True\n",
            "Parameter: encoder.layer.9.attention.output.LayerNorm.weight, requires_grad: True\n",
            "Parameter: encoder.layer.9.attention.output.LayerNorm.bias, requires_grad: True\n",
            "Parameter: encoder.layer.9.intermediate.dense.weight, requires_grad: True\n",
            "Parameter: encoder.layer.9.intermediate.dense.bias, requires_grad: True\n",
            "Parameter: encoder.layer.9.output.dense.weight, requires_grad: True\n",
            "Parameter: encoder.layer.9.output.dense.bias, requires_grad: True\n",
            "Parameter: encoder.layer.9.output.LayerNorm.weight, requires_grad: True\n",
            "Parameter: encoder.layer.9.output.LayerNorm.bias, requires_grad: True\n",
            "Parameter: encoder.layer.10.attention.self.query.weight, requires_grad: True\n",
            "Parameter: encoder.layer.10.attention.self.query.bias, requires_grad: True\n",
            "Parameter: encoder.layer.10.attention.self.key.weight, requires_grad: True\n",
            "Parameter: encoder.layer.10.attention.self.key.bias, requires_grad: True\n",
            "Parameter: encoder.layer.10.attention.self.value.weight, requires_grad: True\n",
            "Parameter: encoder.layer.10.attention.self.value.bias, requires_grad: True\n",
            "Parameter: encoder.layer.10.attention.output.dense.weight, requires_grad: True\n",
            "Parameter: encoder.layer.10.attention.output.dense.bias, requires_grad: True\n",
            "Parameter: encoder.layer.10.attention.output.LayerNorm.weight, requires_grad: True\n",
            "Parameter: encoder.layer.10.attention.output.LayerNorm.bias, requires_grad: True\n",
            "Parameter: encoder.layer.10.intermediate.dense.weight, requires_grad: True\n",
            "Parameter: encoder.layer.10.intermediate.dense.bias, requires_grad: True\n",
            "Parameter: encoder.layer.10.output.dense.weight, requires_grad: True\n",
            "Parameter: encoder.layer.10.output.dense.bias, requires_grad: True\n",
            "Parameter: encoder.layer.10.output.LayerNorm.weight, requires_grad: True\n",
            "Parameter: encoder.layer.10.output.LayerNorm.bias, requires_grad: True\n",
            "Parameter: encoder.layer.11.attention.self.query.weight, requires_grad: True\n",
            "Parameter: encoder.layer.11.attention.self.query.bias, requires_grad: True\n",
            "Parameter: encoder.layer.11.attention.self.key.weight, requires_grad: True\n",
            "Parameter: encoder.layer.11.attention.self.key.bias, requires_grad: True\n",
            "Parameter: encoder.layer.11.attention.self.value.weight, requires_grad: True\n",
            "Parameter: encoder.layer.11.attention.self.value.bias, requires_grad: True\n",
            "Parameter: encoder.layer.11.attention.output.dense.weight, requires_grad: True\n",
            "Parameter: encoder.layer.11.attention.output.dense.bias, requires_grad: True\n",
            "Parameter: encoder.layer.11.attention.output.LayerNorm.weight, requires_grad: True\n",
            "Parameter: encoder.layer.11.attention.output.LayerNorm.bias, requires_grad: True\n",
            "Parameter: encoder.layer.11.intermediate.dense.weight, requires_grad: True\n",
            "Parameter: encoder.layer.11.intermediate.dense.bias, requires_grad: True\n",
            "Parameter: encoder.layer.11.output.dense.weight, requires_grad: True\n",
            "Parameter: encoder.layer.11.output.dense.bias, requires_grad: True\n",
            "Parameter: encoder.layer.11.output.LayerNorm.weight, requires_grad: True\n",
            "Parameter: encoder.layer.11.output.LayerNorm.bias, requires_grad: True\n"
          ]
        }
      ],
      "source": [
        "for layer_idx in range(1):\n",
        "    for name, param in model.bert.encoder.layer[layer_idx].named_parameters():\n",
        "        param.requires_grad = False\n",
        "for name, param in model.bert.named_parameters():\n",
        "    print(f\"Parameter: {name}, requires_grad: {param.requires_grad}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pFJqjCIcTytU"
      },
      "outputs": [],
      "source": [
        "model.to(device)\n",
        "model.train()\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=8, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False)\n",
        "\n",
        "optim = AdamW(model.parameters(), lr=0.0001,no_deprecation_warning=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TxOmBGW53JDS"
      },
      "source": [
        "# model training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 588
        },
        "id": "1zOqhyABZqas",
        "outputId": "1fbef236-d345-487a-fb13-d5aa401bd01d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15,Train Loss: 2.7712741860976586, Val Loss: 1.963636647571217\n",
            "Epoch 2/15,Train Loss: 1.524397027798188, Val Loss: 1.2272485995834523\n",
            "Epoch 3/15,Train Loss: 0.8398300192008415, Val Loss: 0.973262579264966\n",
            "Epoch 4/15,Train Loss: 0.4754907316886462, Val Loss: 1.0737006970765917\n",
            "Epoch 5/15,Train Loss: 0.3255338975323889, Val Loss: 1.0597977137023753\n",
            "Epoch 6/15,Train Loss: 0.28972838355753666, Val Loss: 1.2690761414441196\n",
            "\n",
            "Early stopping triggered after 3 epochs without improvement.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "epochs = 15\n",
        "\n",
        "# Early stopping variables\n",
        "best_val_loss = float('inf')\n",
        "epochs_since_improvement = 0\n",
        "patience = 3\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    # Training phase\n",
        "    epoch_train_losses = []\n",
        "    model.train()\n",
        "    for batch in train_loader:\n",
        "        optim.zero_grad()\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        start_positions = batch['start_positions'].to(device)\n",
        "        end_positions = batch['end_positions'].to(device)\n",
        "        outputs = model(input_ids, attention_mask=attention_mask, start_positions=start_positions, end_positions=end_positions)\n",
        "        loss = outputs[0]\n",
        "        loss.backward()\n",
        "        optim.step()\n",
        "        epoch_train_losses.append(loss.item())\n",
        "\n",
        "    epoch_train_loss = sum(epoch_train_losses) / len(epoch_train_losses)\n",
        "    train_losses.append(epoch_train_loss)\n",
        "\n",
        "    # Validation phase\n",
        "    epoch_val_losses = []\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for batch in val_loader:\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            start_positions = batch['start_positions'].to(device)\n",
        "            end_positions = batch['end_positions'].to(device)\n",
        "            outputs = model(input_ids, attention_mask=attention_mask, start_positions=start_positions, end_positions=end_positions)\n",
        "            loss = outputs[0]\n",
        "            epoch_val_losses.append(loss.item())\n",
        "\n",
        "    epoch_val_loss = sum(epoch_val_losses) / len(epoch_val_losses)\n",
        "    print(f\"Epoch {epoch + 1}/{epochs},Train Loss: {epoch_train_loss}, Val Loss: {epoch_val_loss}\")\n",
        "    val_losses.append(epoch_val_loss)\n",
        "\n",
        "\n",
        "         # Early stopping check\n",
        "    if epoch_val_loss < best_val_loss:\n",
        "        best_val_loss = epoch_val_loss\n",
        "        epochs_since_improvement = 0\n",
        "        # Save the best model weights (optional)\n",
        "        torch.save(model.state_dict(), 'best_model.pt')\n",
        "    else:\n",
        "        epochs_since_improvement += 1\n",
        "\n",
        "    if epochs_since_improvement >= patience:\n",
        "        print(f\"\\nEarly stopping triggered after {epochs_since_improvement} epochs without improvement.\")\n",
        "        break\n",
        "\n",
        "\n",
        "# Plot the training and validation losses\n",
        "\n",
        "plt.plot(range(1, len(train_losses) + 1), train_losses, label='Train Loss')\n",
        "plt.plot(range(1, len(val_losses) + 1), val_losses, label='Val Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KuqUEYC4Ynh3"
      },
      "source": [
        "# model testing\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KqE0OTJmeM2U",
        "outputId": "05fdef33-a375-411a-d8f7-98887d94f217"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2023.12.25)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install nltk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IhZFsRDgdMQZ"
      },
      "outputs": [],
      "source": [
        "#run it to show the model preformence at the inflection point\n",
        "# try:\n",
        "#   model.load_state_dict(torch.load('best_model.pt'))\n",
        "#   print(\"Loaded best saved model 'best_model.pt'\")\n",
        "# except FileNotFoundError:\n",
        "#   print(\"Best model 'best_model.pt' not found. Continuing with training model.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SMVQ-fK72htv",
        "outputId": "0054cb04-7bd0-4e89-dc0e-447d9a15b0a4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9/9 [00:02<00:00,  3.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "F1 = 0.7867647058823529\n",
            "EM = 0.6617647058823529\n",
            "ACC = 0.7847222222222222\n",
            "BLEU = 0.8225175664839919\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import f1_score\n",
        "from nltk.translate.bleu_score import corpus_bleu\n",
        "from tqdm import tqdm\n",
        "\n",
        "references = []  # List to store the reference sentences\n",
        "hypotheses = []  # List to store the generated/hypothesized sentences\n",
        "acc = []\n",
        "all_start_pred = []\n",
        "all_end_pred = []\n",
        "all_start_true = []\n",
        "all_end_true = []\n",
        "\n",
        "model.eval()\n",
        "\n",
        "for batch in tqdm(test_loader):\n",
        "    with torch.no_grad():\n",
        "\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        start_true = batch['start_positions'].to(device)\n",
        "        end_true = batch['end_positions'].to(device)\n",
        "\n",
        "        # make predictions\n",
        "        outputs = model(input_ids, attention_mask=attention_mask)\n",
        "        # pull preds out\n",
        "        start_pred = torch.argmax(outputs['start_logits'], dim=1)\n",
        "        end_pred = torch.argmax(outputs['end_logits'], dim=1)\n",
        "\n",
        "        # Append predictions and true values for each example\n",
        "        all_start_pred.extend(start_pred.cpu().numpy())\n",
        "        all_end_pred.extend(end_pred.cpu().numpy())\n",
        "        all_start_true.extend(start_true.cpu().numpy())\n",
        "        all_end_true.extend(end_true.cpu().numpy())\n",
        "\n",
        "        # calculate accuracy for both and append to accuracy list\n",
        "        acc.append(((start_pred == start_true).sum()/len(start_pred)).item())\n",
        "        acc.append(((end_pred == end_true).sum()/len(end_pred)).item())\n",
        "\n",
        "        # Convert predictions to sentences\n",
        "        for i in range(len(start_pred)):\n",
        "            start_idx = start_pred[i].item()\n",
        "            end_idx = end_pred[i].item()\n",
        "            input_tokens = tokenizer.convert_ids_to_tokens(input_ids[i])\n",
        "            predicted_tokens = input_tokens[start_idx: end_idx + 1]\n",
        "            predicted_sentence = tokenizer.convert_tokens_to_string(predicted_tokens)\n",
        "            hypotheses.append(predicted_sentence)\n",
        "\n",
        "        # Convert true answers to sentences\n",
        "        for i in range(len(start_true)):\n",
        "            start_idx = start_true[i].item()\n",
        "            end_idx = end_true[i].item()\n",
        "            input_tokens = tokenizer.convert_ids_to_tokens(input_ids[i])\n",
        "            true_tokens = input_tokens[start_idx: end_idx + 1]\n",
        "            true_sentence = tokenizer.convert_tokens_to_string(true_tokens)\n",
        "            references.append([true_sentence])\n",
        "\n",
        "# Calculate F1 score\n",
        "start_f1 = f1_score(all_start_true, all_start_pred, average='micro')\n",
        "end_f1 = f1_score(all_end_true, all_end_pred, average='micro')\n",
        "overall_f1 = (start_f1 + end_f1) / 2\n",
        "\n",
        "\n",
        "# calculate average accuracy in total\n",
        "accuracy = sum(acc) / len(acc)\n",
        "\n",
        "# Calculate Exact Match (EM) score\n",
        "num_exact_matches = 0\n",
        "total_examples = len(all_start_pred)\n",
        "for i in range(total_examples):\n",
        "    start_pred = all_start_pred[i]\n",
        "    end_pred = all_end_pred[i]\n",
        "    start_true = all_start_true[i]\n",
        "    end_true = all_end_true[i]\n",
        "    if start_pred == start_true and end_pred == end_true:\n",
        "        num_exact_matches += 1\n",
        "em = num_exact_matches / total_examples\n",
        "\n",
        "# Calculate BLEU score\n",
        "bleu_score = corpus_bleu(references, hypotheses)\n",
        "\n",
        "print(f'\\nF1 = {overall_f1}')\n",
        "print(f'EM = {em}')\n",
        "print(f'ACC = {accuracy}')\n",
        "print(f'BLEU = {bleu_score}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V-CgtblU3bwn",
        "outputId": "d91bc177-00d3-403e-9591-f5fd3cf1c535"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForQuestionAnswering(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(64000, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (qa_outputs): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "model.eval()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aCUzpXWXY6Rj"
      },
      "source": [
        "# Model saving"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VqaFaN1tYKYb"
      },
      "outputs": [],
      "source": [
        "model_save_path = \"/content/model\"\n",
        "model.save_pretrained(model_save_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pSK9N8yBBRGK",
        "outputId": "0d8df126-e03d-4af7-cfb5-5c73800804ac"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('/content/model/tokenizer_config.json',\n",
              " '/content/model/special_tokens_map.json',\n",
              " '/content/model/vocab.txt',\n",
              " '/content/model/added_tokens.json',\n",
              " '/content/model/tokenizer.json')"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "tokenizer.save_pretrained(model_save_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cE-hlkfjY9iW"
      },
      "source": [
        "# pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fCzFFSn03lDK"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline\n",
        "model = AutoModelForQuestionAnswering.from_pretrained(model_save_path)\n",
        "pipe = pipeline(model = model,\n",
        "        tokenizer= tokenizer,\n",
        "        task=\"question-answering\"\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LZbOQtPhBTgK",
        "outputId": "d81908e3-7484-4acd-c6f8-af66c042e75d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: ماهي استعمالات شجرة الأثاب؟\n",
            "Answer: لتزيين الحدائق والمتنزهات والأرصفة\n"
          ]
        }
      ],
      "source": [
        "context = \"الأثاب هي أشجار خضراء كبيرة جميلة، وارفة الظلال. تصلح لتزيين الحدائق والمتنزهات والأرصفة.\"\n",
        "question = \"ماهي استعمالات شجرة الأثاب؟\"\n",
        "\n",
        "# Perform inference using the pipeline\n",
        "result = pipe(context=context, question=question)\n",
        "\n",
        "# Extract the answer\n",
        "answer = result[\"answer\"]\n",
        "\n",
        "print(\"Question:\", question)\n",
        "print(\"Answer:\", answer)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rfz1l5vE6gjd",
        "outputId": "ad359d78-51bf-4643-e257-e7fcb219a895"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: كم يصل حجم قطر أزهار البوق الذهبي؟\n",
            "Answer: 12 سنتمتر في القطر\n"
          ]
        }
      ],
      "source": [
        "question = \"كم يصل حجم قطر أزهار البوق الذهبي؟\"\n",
        "context =\"شجيرات الألمندا الصفراء من نباتات الزينة الملتفة المتسلقة، وموطنها الأصلي شمال البرازيل. ويمكن أن تشكل تغطية تامة للجدران التي تستند إليها بصورة جذابة. وأزهارها الجذابة صفراء اللون يصل حجمها إلى 12 سنتمتر في القطر.وعند توفر الظروف فإنها تعطي منظرًا وجمالًا مميزًا وتنمو في نورات غير محدودة في أشهر الصيف يتبعها ثمار ذات أشواك لها بذور مجنحة. والأماكن المشمسة جيدة التصريف مهمة لهذه النباتات، في حالة شح المياه فإنها تستمر في النمو، وهي تنمو سريعًا في الترب الرطبة عالية المستوى الرطوبي قليلة الملوحة، كما تتحمل الفترات الباردة ولكن الصقيع يؤثر على الأوراق بسرعة\"\n",
        "result = pipe(context=context, question=question)\n",
        "\n",
        "answer = result[\"answer\"]\n",
        "print(\"Question:\", question)\n",
        "print(\"Answer:\", answer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MIR1uahH6rVi",
        "outputId": "a8bd29f5-6e69-4da6-d0aa-b6b97a1c4630"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: ماهو المناخ المثالي لزراعة ذيل القط الأحمر؟\n",
            "Answer: تحتاج إلى اختيار مواقع مناسبة ظليلة وعالية الرطوبة\n"
          ]
        }
      ],
      "source": [
        "question = \"ماهو المناخ المثالي لزراعة ذيل القط الأحمر؟\"\n",
        "context =\"ويمكن زراعتها بالبذور أو بالأفرع، وتظهر بصورة جميلة في النباتات المؤنثة التي تعطي الأزهار الجميلة، ويمكن أن تتأقلم مع البيئات المشابهة لموطنها الأصلي من حيث الرطوبة العالية إلا أنها غير مناسبة لأجواء الرياض الجافة؛ لذا تحتاج إلى اختيار مواقع مناسبة ظليلة وعالية الرطوبة، ويمكن أن تُتخذ نبات زينة داخليا.\"\n",
        "result = pipe(context=context, question=question)\n",
        "\n",
        "answer = result[\"answer\"]\n",
        "print(\"Question:\", question)\n",
        "print(\"Answer:\", answer)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "YtcApiwYL0-8",
        "aCUzpXWXY6Rj"
      ],
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}